# aad64_Individual_Project_3
Databricks ETL (Extract Transform Load) Pipeline
[![CI](https://github.com/AaryaDesai1/aad64_Individual_Project_3/actions/workflows/actions.yml/badge.svg)](https://github.com/AaryaDesai1/aad64_Individual_Project_3/actions/workflows/actions.yml)

# Summary and Objectives:
This individual project was aimed at understanding how to use Databricks, create an ETL pipeline, and automating the trigger to initiate said pipeline. Furthermore, we needed to create a delta lake to store our data and then use PySpark to conduct data transformations. The following sections will elaborate on the components of this project. 

# Databricks Notebook:
This was made to test the entire ETL pipeline first and ensure that each step was working as need be. This included extraction, loading the data and ingestion, querying the delta lake made using PySpark, transforming said data, and then finally, visualizing the transformed data. 

# PyScripts:
## [extract.py]()

